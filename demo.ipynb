{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molabokchi/bokchi_open_lab/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ![다운로드.png](data:image/png;base64,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) deepdriver quickstart!"
      ],
      "metadata": {
        "id": "ccBiuOu0rtin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "welecome to deepdriver! 😀"
      ],
      "metadata": {
        "id": "ZGV9WnWBrvb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can refer to the guide document.\n",
        "https://bokchi.gitbook.io/deepdriver-ce/"
      ],
      "metadata": {
        "id": "RuepMN3Yyuu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 💻 install deepdriver & requirement package for train"
      ],
      "metadata": {
        "id": "HBGoGa3yQ1TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IQnFbnHdSWLN",
        "outputId": "ef14474c-55a8-440a-88f5-293d9c322f66"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Using cached protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-tools 1.51.1 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.19.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deepdriver==0.0.52"
      ],
      "metadata": {
        "id": "ep81qe8Cs3oZ",
        "outputId": "6519cadd-a485-4aea-9e4b-91bc084995ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepdriver==0.0.52\n",
            "  Downloading deepdriver-0.0.52-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (1.51.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (7.1.2)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (11.4.1)\n",
            "Requirement already satisfied: assertpy in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (2.23.0)\n",
            "Requirement already satisfied: grpcio-tools in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (1.51.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (0.38.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (5.4.8)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.0.52) (5.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from grpcio-tools->deepdriver==0.0.52) (57.4.0)\n",
            "Collecting protobuf<5.0dev,>=4.21.6\n",
            "  Using cached protobuf-4.21.11-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepdriver==0.0.52) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepdriver==0.0.52) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepdriver==0.0.52) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->deepdriver==0.0.52) (8.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.0.52) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.0.52) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.0.52) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.0.52) (2.10)\n",
            "Installing collected packages: protobuf, deepdriver\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "  Attempting uninstall: deepdriver\n",
            "    Found existing installation: deepdriver 0.0.51\n",
            "    Uninstalling deepdriver-0.0.51:\n",
            "      Successfully uninstalled deepdriver-0.0.51\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.11 which is incompatible.\n",
            "tensorflow-metadata 1.11.0 requires protobuf<4,>=3.13, but you have protobuf 4.21.11 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.11 which is incompatible.\u001b[0m\n",
            "Successfully installed deepdriver-0.0.52 protobuf-4.21.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "deepdriver"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install protobuf==3.20.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "zPlF7uZyT6LN",
        "outputId": "8aae6baa-00fa-403a-e460-b37094dca439"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.0\n",
            "  Using cached protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.11\n",
            "    Uninstalling protobuf-4.21.11:\n",
            "      Successfully uninstalled protobuf-4.21.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpcio-tools 1.51.1 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.57.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. ➕ import deepdriver & deeplearnig framework\n",
        "\n"
      ],
      "metadata": {
        "id": "XHyfUGRdRGJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t2G8rFYSMxe8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepdriver"
      ],
      "metadata": {
        "id": "nMIZhc0aye6k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. prepare dataset"
      ],
      "metadata": {
        "id": "bW1624UeFQS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "-O /tmp/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p64rEhWJI01",
        "outputId": "8061b05e-3beb-4419-8f2f-9b63c3b67334"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-14 08:53:56--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 142.250.4.128, 74.125.24.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  19.8MB/s    in 4.2s    \n",
            "\n",
            "2022-12-14 08:54:00 (15.7 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "train_dir = '/content/cat_dog/'\n",
        "shutil.rmtree(train_dir)\n",
        "os.mkdir(train_dir)\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "data_dir ='/tmp/cats_and_dogs_filtered/train'\n",
        "data_doc_dir='/tmp/cats_and_dogs_filtered/train/dogs'\n",
        "data_cat_dir='/tmp/cats_and_dogs_filtered/train/cats'\n",
        "valid_dir ='/tmp/cats_and_dogs_filtered/validation'\n",
        "data_dog_valid_dir='/tmp/cats_and_dogs_filtered/validation/dogs'\n",
        "data_cat_valid_dir='/tmp/cats_and_dogs_filtered/validation/cats'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "zhLshy2aFOtU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train용 폴더 생성\n",
        "train_set_dir = os.path.join(train_dir, 'train_set')\n",
        "os.mkdir(train_set_dir)\n",
        "train_dog_dir = os.path.join(train_set_dir, 'dog')\n",
        "os.mkdir(train_dog_dir)\n",
        "train_cat_dir = os.path.join(train_set_dir, 'cat')\n",
        "os.mkdir(train_cat_dir)\n",
        "# valid용 폴더 생성\n",
        "valid_set_dir = os.path.join(train_dir, 'valid_set')\n",
        "os.mkdir(valid_set_dir)\n",
        "valid_dog_dir = os.path.join(valid_set_dir, 'dog')\n",
        "os.mkdir(valid_dog_dir)\n",
        "valid_cat_dir = os.path.join(valid_set_dir, 'cat')\n",
        "os.mkdir(valid_cat_dir)\n",
        "# test용 폴더 생성\n",
        "test_set_dir = os.path.join(train_dir, 'test_set')\n",
        "os.mkdir(test_set_dir)\n",
        "test_dog_dir = os.path.join(test_set_dir, 'dog')\n",
        "os.mkdir(test_dog_dir)\n",
        "test_cat_dir = os.path.join(test_set_dir, 'cat')\n",
        "os.mkdir(test_cat_dir)"
      ],
      "metadata": {
        "id": "v2zaZn9DJXgL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image file name list 생성\n",
        "import shutil\n",
        "total_data_count =500\n",
        "train_data_count =300\n",
        "test_data_count = 100\n",
        "valid_data_count =100\n",
        "dog_files = [f'dog.{i}.jpg' for i in range(total_data_count)]\n",
        "cat_files = [f'cat.{i}.jpg' for i in range(total_data_count)]\n",
        "\n",
        " \n",
        "# 각 폴더로 image 이동\n",
        "for file in dog_files[:train_data_count]:\n",
        "    src = os.path.join(data_doc_dir, file)\n",
        "    dst = os.path.join(train_dog_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "    \n",
        "for file in dog_files[train_data_count:train_data_count+test_data_count]:\n",
        "    src = os.path.join(data_doc_dir, file)\n",
        "    dst = os.path.join(valid_dog_dir, file)\n",
        "    shutil.move(src, dst)\n",
        " \n",
        "for file in dog_files[train_data_count+test_data_count:total_data_count]:\n",
        "    src = os.path.join(data_doc_dir, file)\n",
        "    dst = os.path.join(test_dog_dir, file)\n",
        "    shutil.move(src, dst)\n",
        " \n",
        "for file in cat_files[:train_data_count]:\n",
        "    src = os.path.join(data_cat_dir, file)\n",
        "    dst = os.path.join(train_cat_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "    \n",
        "for file in cat_files[train_data_count:train_data_count+test_data_count]:\n",
        "    src = os.path.join(data_cat_dir, file)\n",
        "    dst = os.path.join(valid_cat_dir, file)\n",
        "    shutil.move(src, dst)\n",
        " \n",
        "for file in cat_files[train_data_count+test_data_count:total_data_count]:\n",
        "    src = os.path.join(data_cat_dir, file)\n",
        "    dst = os.path.join(test_cat_dir, file)\n",
        "    shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "jtZQt0odOq_U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cat_fnames = os.listdir( train_cat_dir )\n",
        "train_dog_fnames = os.listdir( train_dog_dir )"
      ],
      "metadata": {
        "id": "zwuVLt8dRf4q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total training cat images :', len(os.listdir(train_cat_dir)))\n",
        "print('Total training dog images :', len(os.listdir(train_dog_dir)))\n",
        "\n",
        "print('Total validation cat images :', len(os.listdir(valid_cat_dir)))\n",
        "print('Total validation dog images :', len(os.listdir(valid_dog_dir)))\n",
        "\n",
        "\n",
        "print('Total test cat images :', len(os.listdir(test_cat_dir)))\n",
        "print('Total test dog images :', len(os.listdir(test_dog_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWtzjLavRlLj",
        "outputId": "937d17e7-145c-4554-96de-9424aefdb0d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training cat images : 300\n",
            "Total training dog images : 300\n",
            "Total validation cat images : 100\n",
            "Total validation dog images : 100\n",
            "Total test cat images : 100\n",
            "Total test dog images : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. ⚙ deepdriver server setting"
      ],
      "metadata": {
        "id": "FG0DGtb2VhXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.setting(http_host=\"quick-experience.bokchi.com:9011\" ,grpc_host=\"quick-experience.bokchi.com:19051\")"
      ],
      "metadata": {
        "id": "XDfF___IVcC2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 🔌 log in to deepdriver"
      ],
      "metadata": {
        "id": "36Y_KWmfRYwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.login(key=\"MGY2ZWY5NjY0NjE3YjVkODBhNGRkYjBkZDAzYzQ5MGMxMzVhZWRhNzkyYTdiNDI4ZGZmYjZmZDhmYzdkY2I3ZQ==\")"
      ],
      "metadata": {
        "id": "hF3GenoNsaBQ",
        "outputId": "3d273d3d-2180-4b8d-e37d-17661e058714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. 🥼 create experiment and run"
      ],
      "metadata": {
        "id": "gWafO8QnRpc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment init & config hyperparam\n",
        "deepdriver.init(exp_name= \"cat_dog_cnn\", \n",
        "                config={ 'architecture':\"CNN\", 'epoch': 30, 'batch_size': 128, 'hidden_layer':512, 'learning_rate': 0.001})"
      ],
      "metadata": {
        "id": "z93NrRBUsvDm",
        "outputId": "feb7f419-5e0c-4e37-9c9f-5d3d676f79fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-14 08:54:03,481 INFO [deepdriver] [experiment.py:21] - DeepDriver initialized\n",
            "Team Name=molamola.babo\n",
            "Exp Name=cat_dog_cnn\n",
            "Run Name=run-1\n",
            "Run URL=http://quick-experience.bokchi.com:9111/experi/molamola.babo/cat_dog_cnn/run-1/run/chart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepdriver:DeepDriver initialized\n",
            "Team Name=molamola.babo\n",
            "Exp Name=cat_dog_cnn\n",
            "Run Name=run-1\n",
            "Run URL=http://quick-experience.bokchi.com:9111/experi/molamola.babo/cat_dog_cnn/run-1/run/chart\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<deepdriver.sdk.data_types.run.Run at 0x7fa37a8a2730>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 📚 train your code and send log"
      ],
      "metadata": {
        "id": "CNDciDDURuZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make model"
      ],
      "metadata": {
        "id": "wbFA68eYps1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(deepdriver.config.hidden_layer, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qga-dT4iRyR6",
        "outputId": "af3135dc-7adc-46fa-eab3-2261adeb1817"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18496)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               9470464   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,494,561\n",
            "Trainable params: 9,494,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=deepdriver.config.learning_rate),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "dHinKbNnRyUv",
        "outputId": "4eb1cd70-2757-47df-f616-26bc48c78093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data load"
      ],
      "metadata": {
        "id": "CHW9p5NypwdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "valid_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_set_dir,\n",
        "                                                  batch_size=deepdriver.config.batch_size,\n",
        "                                                  class_mode='binary',\n",
        "                                                  target_size=(150, 150))\n",
        "validation_generator =  valid_datagen.flow_from_directory(valid_set_dir,\n",
        "                                                       batch_size=deepdriver.config.batch_size,\n",
        "                                                       class_mode  = 'binary',\n",
        "                                                       target_size = (150, 150))\n",
        "\n",
        "test_generator =  test_datagen.flow_from_directory(test_set_dir,\n",
        "                                                       batch_size=deepdriver.config.batch_size,\n",
        "                                                       class_mode  = 'binary',\n",
        "                                                       target_size = (150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3x9kB6MVClP",
        "outputId": "df9a1989-e4e9-44ce-92a0-ad94d5e14a60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add deepdriver.log() in train function"
      ],
      "metadata": {
        "id": "3ecGvoxzp-Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        deepdriver.finish()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        keys = list(logs.keys())\n",
        "        deepdriver.log({\"acc\": logs[\"accuracy\"], \"loss\": logs[\"loss\"], \"val_acc\": logs[\"val_accuracy\"], \"val_loss\": logs[\"val_loss\"]})\n",
        "        #deepdriver.log(logs)\n"
      ],
      "metadata": {
        "id": "O9oUAVd0X8qS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model"
      ],
      "metadata": {
        "id": "6JmoZzikqNRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.n//deepdriver.config.batch_size"
      ],
      "metadata": {
        "id": "2zXQzAUUZP1C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_steps = validation_generator.n//deepdriver.config.batch_size"
      ],
      "metadata": {
        "id": "rI4UVyABZQcy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=deepdriver.config.epoch,\n",
        "                    validation_steps=validation_steps ,\n",
        "                    callbacks=[CustomCallback()],\n",
        "                    verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF8hsCeJXcIt",
        "outputId": "a0e1eb48-3f54-4202-871d-8e14dccd718e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "4/4 - 8s - loss: 5.7217 - accuracy: 0.5233 - val_loss: 0.7131 - val_accuracy: 0.5078 - 8s/epoch - 2s/step\n",
            "Epoch 2/30\n",
            "4/4 - 2s - loss: 0.7393 - accuracy: 0.4936 - val_loss: 0.6979 - val_accuracy: 0.5000 - 2s/epoch - 533ms/step\n",
            "Epoch 3/30\n",
            "4/4 - 2s - loss: 0.7474 - accuracy: 0.5360 - val_loss: 0.6927 - val_accuracy: 0.5469 - 2s/epoch - 536ms/step\n",
            "Epoch 4/30\n",
            "4/4 - 2s - loss: 0.6726 - accuracy: 0.6017 - val_loss: 0.6800 - val_accuracy: 0.6094 - 2s/epoch - 534ms/step\n",
            "Epoch 5/30\n",
            "4/4 - 2s - loss: 0.7679 - accuracy: 0.5508 - val_loss: 0.6868 - val_accuracy: 0.5469 - 2s/epoch - 542ms/step\n",
            "Epoch 6/30\n",
            "4/4 - 2s - loss: 0.6996 - accuracy: 0.6314 - val_loss: 0.6850 - val_accuracy: 0.5625 - 2s/epoch - 554ms/step\n",
            "Epoch 7/30\n",
            "4/4 - 2s - loss: 0.6222 - accuracy: 0.7373 - val_loss: 0.7084 - val_accuracy: 0.5469 - 2s/epoch - 556ms/step\n",
            "Epoch 8/30\n",
            "4/4 - 2s - loss: 0.9170 - accuracy: 0.6059 - val_loss: 0.6902 - val_accuracy: 0.5312 - 2s/epoch - 543ms/step\n",
            "Epoch 9/30\n",
            "4/4 - 2s - loss: 0.6128 - accuracy: 0.6568 - val_loss: 0.6317 - val_accuracy: 0.6562 - 2s/epoch - 528ms/step\n",
            "Epoch 10/30\n",
            "4/4 - 2s - loss: 0.7037 - accuracy: 0.5869 - val_loss: 0.6706 - val_accuracy: 0.5469 - 2s/epoch - 546ms/step\n",
            "Epoch 11/30\n",
            "4/4 - 2s - loss: 0.5788 - accuracy: 0.7479 - val_loss: 0.6786 - val_accuracy: 0.5625 - 2s/epoch - 534ms/step\n",
            "Epoch 12/30\n",
            "4/4 - 2s - loss: 0.6042 - accuracy: 0.6483 - val_loss: 0.6768 - val_accuracy: 0.5781 - 2s/epoch - 537ms/step\n",
            "Epoch 13/30\n",
            "4/4 - 2s - loss: 0.5359 - accuracy: 0.7754 - val_loss: 0.6763 - val_accuracy: 0.6172 - 2s/epoch - 538ms/step\n",
            "Epoch 14/30\n",
            "4/4 - 2s - loss: 0.4938 - accuracy: 0.7988 - val_loss: 0.6654 - val_accuracy: 0.6641 - 2s/epoch - 547ms/step\n",
            "Epoch 15/30\n",
            "4/4 - 2s - loss: 0.5407 - accuracy: 0.7129 - val_loss: 0.6662 - val_accuracy: 0.5859 - 2s/epoch - 546ms/step\n",
            "Epoch 16/30\n",
            "4/4 - 2s - loss: 0.5625 - accuracy: 0.7203 - val_loss: 0.7260 - val_accuracy: 0.5000 - 2s/epoch - 561ms/step\n",
            "Epoch 17/30\n",
            "4/4 - 3s - loss: 0.4833 - accuracy: 0.7881 - val_loss: 0.7301 - val_accuracy: 0.5859 - 3s/epoch - 704ms/step\n",
            "Epoch 18/30\n",
            "4/4 - 2s - loss: 0.4693 - accuracy: 0.7627 - val_loss: 0.7324 - val_accuracy: 0.5469 - 2s/epoch - 555ms/step\n",
            "Epoch 19/30\n",
            "4/4 - 2s - loss: 0.3990 - accuracy: 0.8093 - val_loss: 0.7165 - val_accuracy: 0.6016 - 2s/epoch - 573ms/step\n",
            "Epoch 20/30\n",
            "4/4 - 2s - loss: 0.4336 - accuracy: 0.8145 - val_loss: 0.7765 - val_accuracy: 0.5547 - 2s/epoch - 556ms/step\n",
            "Epoch 21/30\n",
            "4/4 - 2s - loss: 0.3963 - accuracy: 0.8184 - val_loss: 0.9117 - val_accuracy: 0.5703 - 2s/epoch - 536ms/step\n",
            "Epoch 22/30\n",
            "4/4 - 2s - loss: 0.4147 - accuracy: 0.8178 - val_loss: 0.8125 - val_accuracy: 0.6328 - 2s/epoch - 541ms/step\n",
            "Epoch 23/30\n",
            "4/4 - 2s - loss: 0.3216 - accuracy: 0.8517 - val_loss: 0.7630 - val_accuracy: 0.5781 - 2s/epoch - 538ms/step\n",
            "Epoch 24/30\n",
            "4/4 - 2s - loss: 0.3263 - accuracy: 0.8453 - val_loss: 1.0996 - val_accuracy: 0.4766 - 2s/epoch - 533ms/step\n",
            "Epoch 25/30\n",
            "4/4 - 2s - loss: 0.3652 - accuracy: 0.8369 - val_loss: 0.7089 - val_accuracy: 0.6328 - 2s/epoch - 533ms/step\n",
            "Epoch 26/30\n",
            "4/4 - 2s - loss: 0.2634 - accuracy: 0.8941 - val_loss: 0.9178 - val_accuracy: 0.5781 - 2s/epoch - 547ms/step\n",
            "Epoch 27/30\n",
            "4/4 - 2s - loss: 0.1767 - accuracy: 0.9301 - val_loss: 1.3689 - val_accuracy: 0.5469 - 2s/epoch - 550ms/step\n",
            "Epoch 28/30\n",
            "4/4 - 2s - loss: 0.3946 - accuracy: 0.8051 - val_loss: 1.4166 - val_accuracy: 0.5234 - 2s/epoch - 532ms/step\n",
            "Epoch 29/30\n",
            "4/4 - 2s - loss: 0.2616 - accuracy: 0.8898 - val_loss: 1.0258 - val_accuracy: 0.5703 - 2s/epoch - 540ms/step\n",
            "Epoch 30/30\n",
            "4/4 - 2s - loss: 0.1489 - accuracy: 0.9534 - val_loss: 1.0843 - val_accuracy: 0.6094 - 2s/epoch - 524ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"cat_dog_cnn_model\")"
      ],
      "metadata": {
        "id": "kPeoZ7K5YXSp",
        "outputId": "11dc37bf-bbdf-4167-ee5f-3a481bf2b0d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. ⬆ upload artifact(Model)"
      ],
      "metadata": {
        "id": "b4SVJ4HcKugj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arti = deepdriver.Artifacts(name=\"cat_dog_cnn_model\",type=\"model\")"
      ],
      "metadata": {
        "id": "TxgovR2JKt4y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arti.add(\"cat_dog_cnn_model\")"
      ],
      "metadata": {
        "id": "hhsY3_lVLR6T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[ent.path for ent  in arti.entry_list]"
      ],
      "metadata": {
        "id": "rJ0sHNYM0oOP",
        "outputId": "25cf3d46-f2bd-452b-a47f-d41865b5f6fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['saved_model.pb',\n",
              " 'variables/variables.index',\n",
              " 'variables/variables.data-00000-of-00001',\n",
              " 'keras_metadata.pb']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arti.upload()"
      ],
      "metadata": {
        "id": "Ojc77RQKbi8m",
        "outputId": "721d6dc4-f59a-47c7-cb20-47fc29cf6f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading: [./cat_dog_cnn_model/keras_metadata.pb] |██████████████████████████████| [100.0%] [4/4]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.finish()"
      ],
      "metadata": {
        "id": "36ARN62es0rC",
        "outputId": "d849e2f8-3d47-4ead-c71a-d9cebb9abaa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. ⬇ create another run & download artifact(Model)"
      ],
      "metadata": {
        "id": "Ls72Ap0WLywJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment init & config hyperparam\n",
        "deepdriver.init(exp_name= \"cat_dog_cnn\", \n",
        "                config={ 'architecture':\"CNN\", 'epoch': 10, 'batch_size': 128, 'hidden_layer':512, 'learning_rate': 0.001})"
      ],
      "metadata": {
        "id": "WIs3oC7asCP6",
        "outputId": "4968c3d5-f93f-44a8-9c29-8198f3f3f07b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-14 08:55:54,278 INFO [deepdriver] [experiment.py:21] - DeepDriver initialized\n",
            "Team Name=molamola.babo\n",
            "Exp Name=cat_dog_cnn\n",
            "Run Name=run-2\n",
            "Run URL=http://quick-experience.bokchi.com:9111/experi/molamola.babo/cat_dog_cnn/run-2/run/chart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepdriver:DeepDriver initialized\n",
            "Team Name=molamola.babo\n",
            "Exp Name=cat_dog_cnn\n",
            "Run Name=run-2\n",
            "Run URL=http://quick-experience.bokchi.com:9111/experi/molamola.babo/cat_dog_cnn/run-2/run/chart\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<deepdriver.sdk.data_types.run.Run at 0x7fa360383a60>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arti2 = deepdriver.get_artifact(name=\"cat_dog_cnn_model\",type=\"model\")"
      ],
      "metadata": {
        "id": "b3e58_uUL5gu",
        "outputId": "1aa55cbd-bc75-472f-d22f-62f97cec0eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-14 08:55:54,959 INFO [deepdriver] [run.py:38] - artifact is got! \n",
            " artifact id :{17}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:deepdriver:artifact is got! \n",
            " artifact id :{17}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arti2.download()"
      ],
      "metadata": {
        "id": "7gSoGrP9MNls",
        "outputId": "4dd28c1f-c34e-4d20-c6c0-b3fde26c920c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: [./deepdriver/artifact/17/variables/variables.index] |██████████████████████████████| [100.0%] [4/4]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./deepdriver/artifact/17'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. model re-train & upload model with another version"
      ],
      "metadata": {
        "id": "GqP6VGdVyFvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reload_model = tf.keras.models.load_model(arti2.get_download_dir())"
      ],
      "metadata": {
        "id": "49Cz_wrXiyIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "93ff885d-a14f-45f9-d333-555bcf6eda65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f610d26333b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreload_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marti2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_download_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Artifacts' object has no attribute 'get_download_dir'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = reload_model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=deepdriver.config.epoch,\n",
        "                    validation_steps=validation_steps ,\n",
        "                    callbacks=[CustomCallback()],\n",
        "                    verbose=2)"
      ],
      "metadata": {
        "id": "VS0s5I91l225"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reload_model.save(\"cat_dog_cnn_model2\")"
      ],
      "metadata": {
        "id": "ff_2bMA2oI0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arti = deepdriver.get_artifact(name=\"cat_dog_cnn_model\",type=\"model\")"
      ],
      "metadata": {
        "id": "bFtHE3IroQDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arti.add(\"cat_dog_cnn_model2\")"
      ],
      "metadata": {
        "id": "hBTWUVB-oXRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arti.upload()"
      ],
      "metadata": {
        "id": "AaFL4-dhodJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.finish()"
      ],
      "metadata": {
        "id": "CGRnS7qPs55S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0fhh84MKyRN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}