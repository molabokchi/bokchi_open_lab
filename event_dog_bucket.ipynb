{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molabokchi/bokchi_open_lab/blob/main/event_dog_bucket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXwQGFizUEAg",
        "tags": []
      },
      "outputs": [],
      "source": [
        "## reinstall diffusers 0.2.4\n",
        "## TODO: you should restart kernel\n",
        "\n",
        "#!pip install diffusers==0.8.0\n",
        "\n",
        "#! pip install diffusers==0.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moqQMoLSzjUF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "! pip --version\n",
        "! python --version\n",
        "! nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "bHCqxXvRtPuC"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers==0.14.0\n",
        "#!pip install transformers scipy ftfy accelerate\n",
        "!pip install transformers scipy ftfy accelerate\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaNtmAA6zLc0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "! rm -rf diffusers\n",
        "! git clone https://github.com/huggingface/diffusers\n",
        "! cd diffusers && git checkout v0.14.0 && pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nHQLSxrz3_h",
        "tags": []
      },
      "outputs": [],
      "source": [
        "! cd diffusers/examples/dreambooth && pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIKpdGpD05MG"
      },
      "outputs": [],
      "source": [
        "! accelerate config default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0koQpSv1PSi"
      },
      "outputs": [],
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "!rm ~/.cache/huggingface/accelerate/default_config.yaml\n",
        "write_basic_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN9CjH6WhjL4"
      },
      "outputs": [],
      "source": [
        "! pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4PNXWCHhsbv"
      },
      "outputs": [],
      "source": [
        "! pip install -U xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP8iMPXRYyPc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "! curl -sSL -O https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/instance-images.tar.gz\n",
        "\n",
        "!tar -xzvf instance-images.tar.gz\n",
        "\n",
        "! rm -rf ./instance-images/.ipynb_checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M5CEDfMlEtF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "### 12GB GPU\n",
        "\n",
        "#export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
        "#export INSTANCE_DIR=\"path-to-instance-images\"\n",
        "#export CLASS_DIR=\"path-to-class-images\"\n",
        "#export OUTPUT_DIR=\"path-to-save-model\"\n",
        "\n",
        "! accelerate launch ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4  \\\n",
        "  --instance_data_dir=./instance-images \\\n",
        "  --class_data_dir=./class_dir \\\n",
        "  --output_dir=./output \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --instance_prompt=\"a photo of sks dog\" \\\n",
        "  --class_prompt=\"a photo of dog\" \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "  --use_8bit_adam \\\n",
        "  --enable_xformers_memory_efficient_attention \\\n",
        "  --set_grads_to_none \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=200 \\\n",
        "  --max_train_steps=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTaz0ZVPZKY5"
      },
      "outputs": [],
      "source": [
        "## 16GB GPU\n",
        "\n",
        "\n",
        "\n",
        "# export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
        "# export INSTANCE_DIR=\"path-to-instance-images\"\n",
        "# export CLASS_DIR=\"path-to-class-images\"\n",
        "# export OUTPUT_DIR=\"path-to-save-model\"\n",
        "\n",
        "# ! accelerate launch ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#   --pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4  \\\n",
        "#   --instance_data_dir=/content/instance_image \\\n",
        "#   --class_data_dir=/content/class_dir \\\n",
        "#   --output_dir=/content/output \\\n",
        "#   --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "#   --instance_prompt=\"a photo of sks dog\" \\\n",
        "#   --class_prompt=\"a photo of dog\" \\\n",
        "#   --resolution=512 \\\n",
        "#   --train_batch_size=1 \\\n",
        "#   --gradient_accumulation_steps=2 --gradient_checkpointing \\\n",
        "#   --use_8bit_adam \\\n",
        "#   --learning_rate=5e-6 \\\n",
        "#   --lr_scheduler=\"constant\" \\\n",
        "#   --lr_warmup_steps=0 \\\n",
        "#   --num_class_images=200 \\\n",
        "#   --max_train_steps=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4hYL5niZKdz"
      },
      "outputs": [],
      "source": [
        "\n",
        "## 8GPU, VRAM\n",
        "\n",
        "# ! accelerate launch --mixed_precision=\"fp16\" ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#   --pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4 \\\n",
        "#   --instance_data_dir=/content/instance_image \\\n",
        "#   --class_data_dir=/content/class_dir \\\n",
        "#   --output_dir=/content/output \\\n",
        "#   --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "#   --instance_prompt=\"a photo of sks dog\" \\\n",
        "#   --class_prompt=\"a photo of dog\" \\\n",
        "#   --resolution=512 \\\n",
        "#   --train_batch_size=1 \\\n",
        "#   --sample_batch_size=1 \\\n",
        "#   --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "#   --learning_rate=5e-6 \\\n",
        "#   --lr_scheduler=\"constant\" \\\n",
        "#   --lr_warmup_steps=0 \\\n",
        "#   --num_class_images=200 \\\n",
        "#   --max_train_steps=800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOeqeqlWP4b_"
      },
      "outputs": [],
      "source": [
        "# from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
        "# from transformers import CLIPTextModel\n",
        "# import torch\n",
        "\n",
        "# # Load the pipeline with the same arguments (model, revision) that were used for training\n",
        "# model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "# unet = UNet2DConditionModel.from_pretrained(\"/content/output/checkpoint-500/unet\")\n",
        "\n",
        "# # if you have trained with `--args.train_text_encoder` make sure to also load the text encoder\n",
        "# text_encoder = CLIPTextModel.from_pretrained(\"/content/output/text_encoder\")\n",
        "\n",
        "# pipeline = DiffusionPipeline.from_pretrained(model_id, unet=unet, text_encoder=text_encoder, dtype=torch.float16)\n",
        "# pipeline.to(\"cuda\")\n",
        "\n",
        "# # Perform inference, or save, or push to the hub\n",
        "# pipeline.save_pretrained(\"dreambooth-pipeline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8TVjUgOxXHF"
      },
      "outputs": [],
      "source": [
        "# ! pip install --upgrade diffusers transformers accelerate\n",
        "\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"./output\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "prompt = \"A photo of sks dog in a bucket\"\n",
        "image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
        "\n",
        "image.save(\"dog-bucket.png\")\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5rlLy2vy04a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "num_cols = 3\n",
        "num_rows = 4\n",
        "\n",
        "#prompt = [\"a photograph of an astronaut riding a horse\"] * num_cols\n",
        "prompt = [\"a photo of sks dog in a bucket\"] * num_cols\n",
        "\n",
        "all_images = []\n",
        "for i in range(num_rows):\n",
        "  images = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images\n",
        "  all_images.extend(images)\n",
        "\n",
        "grid = image_grid(all_images, rows=num_rows, cols=num_cols)\n",
        "grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43_K8PaytPui"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}