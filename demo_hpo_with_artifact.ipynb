{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molabokchi/bokchi_open_lab/blob/main/demo_hpo_with_artifact.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ![다운로드.png](data:image/png;base64,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) deepdriver hpo quickstart!"
      ],
      "metadata": {
        "id": "ccBiuOu0rtin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "welecome to deepdriver! 😀"
      ],
      "metadata": {
        "id": "ZGV9WnWBrvb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can refer to the guide document.\n",
        "https://bokchi.gitbook.io/deepdriver-ce/"
      ],
      "metadata": {
        "id": "RuepMN3Yyuu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 💻 install deepdriver & requirement package for train"
      ],
      "metadata": {
        "id": "HBGoGa3yQ1TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQnFbnHdSWLN",
        "outputId": "86d677b2-16ee-414d-d466-7b747faf769f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Using cached protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-tools 1.51.1 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.19.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deepdriver==0.7.3"
      ],
      "metadata": {
        "id": "ep81qe8Cs3oZ",
        "outputId": "918cb2dc-8cf3-4c01-fb42-dbd46a3dbbe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepdriver==0.7.3\n",
            "  Downloading deepdriver-0.7.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pynvml in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (11.4.1)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (2.9.5)\n",
            "Requirement already satisfied: grpcio-tools in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (1.51.1)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (1.51.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (1.21.6)\n",
            "Requirement already satisfied: assertpy in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (7.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (5.4.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (0.38.4)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (3.1.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from deepdriver==0.7.3) (2.25.1)\n",
            "Collecting protobuf<5.0dev,>=4.21.6\n",
            "  Using cached protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from grpcio-tools->deepdriver==0.7.3) (57.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (4.64.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (1.9.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (6.7.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (6.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna->deepdriver==0.7.3) (1.4.46)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepdriver==0.7.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepdriver==0.7.3) (2022.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly->deepdriver==0.7.3) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->deepdriver==0.7.3) (8.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.7.3) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.7.3) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.7.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->deepdriver==0.7.3) (4.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna->deepdriver==0.7.3) (5.10.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna->deepdriver==0.7.3) (1.2.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna->deepdriver==0.7.3) (6.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna->deepdriver==0.7.3) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna->deepdriver==0.7.3) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna->deepdriver==0.7.3) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna->deepdriver==0.7.3) (2.0.1)\n",
            "Installing collected packages: protobuf, deepdriver\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.0\n",
            "    Uninstalling protobuf-3.20.0:\n",
            "      Successfully uninstalled protobuf-3.20.0\n",
            "  Attempting uninstall: deepdriver\n",
            "    Found existing installation: deepdriver 0.7.2\n",
            "    Uninstalling deepdriver-0.7.2:\n",
            "      Successfully uninstalled deepdriver-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 4.21.12 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepdriver-0.7.3 protobuf-4.21.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install protobuf==3.20.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPlF7uZyT6LN",
        "outputId": "ef3a99e9-e719-4e34-c3ba-e50471e4311f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.0\n",
            "  Using cached protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.12\n",
            "    Uninstalling protobuf-4.21.12:\n",
            "      Successfully uninstalled protobuf-4.21.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpcio-tools 1.51.1 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.17.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bfcPYMuKmwab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. ➕ import deepdriver & deeplearnig framework\n",
        "\n"
      ],
      "metadata": {
        "id": "XHyfUGRdRGJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t2G8rFYSMxe8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepdriver"
      ],
      "metadata": {
        "id": "nMIZhc0aye6k"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. ⚙ deepdriver server setting"
      ],
      "metadata": {
        "id": "FG0DGtb2VhXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.setting(http_host=\"54.180.86.146:9011\" ,grpc_host=\"54.180.86.146:19051\")"
      ],
      "metadata": {
        "id": "XDfF___IVcC2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 🔌 log in to deepdriver"
      ],
      "metadata": {
        "id": "36Y_KWmfRYwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.login(key=\"ZmIyNWQxNGJkMzUxYTVjODQ2NjM5NTgzOTM0YTM2OGE2ZmJiY2M2MWMwOWQ0OWFkNjU2YzNkM2UxMjA0YTVkZg==\")"
      ],
      "metadata": {
        "id": "hF3GenoNsaBQ",
        "outputId": "d88a8ecf-f561-4112-f510-1a9d7a9e42af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. ⌨ upload data & code ( if you upload aleady, skip)"
      ],
      "metadata": {
        "id": "R5Mb2C2docNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate https://raw.githubusercontent.com/molabokchi/bokchi_open_lab/main/main.py -O main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C84yhBQ2UMuX",
        "outputId": "9279c178-7448-4905-a625-313b5195ef90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 07:11:42--  https://raw.githubusercontent.com/molabokchi/bokchi_open_lab/main/main.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3642 (3.6K) [text/plain]\n",
            "Saving to: ‘main.py’\n",
            "\n",
            "main.py             100%[===================>]   3.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 07:11:42 (56.7 MB/s) - ‘main.py’ saved [3642/3642]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.init(exp_name=\"upload_data_code\")"
      ],
      "metadata": {
        "id": "Hl44wF5Wn3Ii",
        "outputId": "9b4159bd-a208-4deb-9484-9c15063f5400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepDriver initialized\n",
            "Team Name=molamola.python\n",
            "Exp Name=upload_data_code\n",
            "Run Name=run-10\n",
            "Run URL=http://54.180.86.146:9111/experi/molamola.python/upload_data_code/run-10/run/chart\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<deepdriver.sdk.data_types.run.Run at 0x7f71c3be6700>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.upload_code(name=\"cnn_1\",type=\"CODE\",path=\"./\")"
      ],
      "metadata": {
        "id": "qTfhH_Gx5Mvr",
        "outputId": "3c8a5669-c4c5-4dcc-faa2-5bfa5ea4faea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artifact is got! \n",
            " artifact id :{486}\n",
            "Uploading: [./main.py] |██████████████████████████████| [100.0%] [2/2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "-O /tmp/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "YMzMv1F6qBs8",
        "outputId": "5ed5765c-69cb-487b-9a57-06c6eb142cee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 04:24:47--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 74.125.68.128, 74.125.24.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  20.8MB/s    in 3.8s    \n",
            "\n",
            "2023-01-26 04:24:51 (17.1 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "train_dir = '/content/cat_dog/'\n",
        "if os.path.isdir(train_dir):\n",
        "  shutil.rmtree(train_dir)\n",
        "  os.mkdir(train_dir)\n",
        "else:\n",
        "  os.mkdir(train_dir)\n",
        "\n",
        "model_dir = '/content/model'\n",
        "\n",
        "if os.path.isdir(model_dir):\n",
        "  shutil.rmtree(model_dir)\n",
        "  os.mkdir(model_dir)\n",
        "else:\n",
        "  os.mkdir(model_dir)\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "data_dir ='/tmp/cats_and_dogs_filtered/train'\n",
        "data_doc_dir='/tmp/cats_and_dogs_filtered/train/dogs'\n",
        "data_cat_dir='/tmp/cats_and_dogs_filtered/train/cats'\n",
        "valid_dir ='/tmp/cats_and_dogs_filtered/validation'\n",
        "data_dog_valid_dir='/tmp/cats_and_dogs_filtered/validation/dogs'\n",
        "data_cat_valid_dir='/tmp/cats_and_dogs_filtered/validation/cats'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "H3GCfqYLqnMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train용 폴더 생성\n",
        "train_set_dir = os.path.join(train_dir, 'train_set')\n",
        "os.mkdir(train_set_dir)\n",
        "train_dog_dir = os.path.join(train_set_dir, 'dog')\n",
        "os.mkdir(train_dog_dir)\n",
        "train_cat_dir = os.path.join(train_set_dir, 'cat')\n",
        "os.mkdir(train_cat_dir)\n",
        "# valid용 폴더 생성\n",
        "valid_set_dir = os.path.join(train_dir, 'valid_set')\n",
        "os.mkdir(valid_set_dir)\n",
        "valid_dog_dir = os.path.join(valid_set_dir, 'dog')\n",
        "os.mkdir(valid_dog_dir)\n",
        "valid_cat_dir = os.path.join(valid_set_dir, 'cat')\n",
        "os.mkdir(valid_cat_dir)\n",
        "# test용 폴더 생성\n",
        "test_set_dir = os.path.join(train_dir, 'test_set')\n",
        "os.mkdir(test_set_dir)\n",
        "test_dog_dir = os.path.join(test_set_dir, 'dog')\n",
        "os.mkdir(test_dog_dir)\n",
        "test_cat_dir = os.path.join(test_set_dir, 'cat')\n",
        "os.mkdir(test_cat_dir)"
      ],
      "metadata": {
        "id": "96f2QcacqptF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image file name list 생성\n",
        "import shutil\n",
        "total_data_count =1000\n",
        "train_data_count =int(total_data_count*0.8)\n",
        "test_data_count = int(total_data_count*0.1)\n",
        "valid_data_count =total_data_count - train_data_count -test_data_count\n",
        "dog_files = [f'dog.{i}.jpg' for i in range(total_data_count)]\n",
        "cat_files = [f'cat.{i}.jpg' for i in range(total_data_count)]\n",
        "\n",
        " \n",
        "# 각 폴더로 image 이동\n",
        "for file in dog_files[:train_data_count]:\n",
        "    src = os.path.join(data_doc_dir, file)\n",
        "    dst = os.path.join(train_dog_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "    \n",
        "for file in dog_files[train_data_count:train_data_count+test_data_count]:\n",
        "    src = os.path.join(data_doc_dir, file)\n",
        "    dst = os.path.join(valid_dog_dir, file)\n",
        "    shutil.move(src, dst)\n",
        " \n",
        "for file in dog_files[train_data_count+test_data_count:total_data_count]:\n",
        "    src = os.path.join(data_doc_dir, file)\n",
        "    dst = os.path.join(test_dog_dir, file)\n",
        "    shutil.move(src, dst)\n",
        " \n",
        "for file in cat_files[:train_data_count]:\n",
        "    src = os.path.join(data_cat_dir, file)\n",
        "    dst = os.path.join(train_cat_dir, file)\n",
        "    shutil.move(src, dst)\n",
        "    \n",
        "for file in cat_files[train_data_count:train_data_count+test_data_count]:\n",
        "    src = os.path.join(data_cat_dir, file)\n",
        "    dst = os.path.join(valid_cat_dir, file)\n",
        "    shutil.move(src, dst)\n",
        " \n",
        "for file in cat_files[train_data_count+test_data_count:total_data_count]:\n",
        "    src = os.path.join(data_cat_dir, file)\n",
        "    dst = os.path.join(test_cat_dir, file)"
      ],
      "metadata": {
        "id": "jfUgp1olqtW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arti =deepdriver.Artifacts(name=\"cat_dog\",type=\"DATASET\")"
      ],
      "metadata": {
        "id": "OaxyQJYNqwSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arti.add(\"./cat_dog\")"
      ],
      "metadata": {
        "id": "n6wSWFGhq_07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepdriver.upload_artifact(arti)"
      ],
      "metadata": {
        "id": "a2-Vkpu4qG8X",
        "outputId": "2c029a47-01c7-41c2-ad45-4baeb12342af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading: [./cat_dog/test_set/dog/dog.920.jpg] |██████████████████████████████| [100.0%] [1900/1900]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4IkvhPhjxSs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 🥼 create hpo"
      ],
      "metadata": {
        "id": "gWafO8QnRpc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name=\"cat_dog_cnn_hpo_with_artifact_exp\""
      ],
      "metadata": {
        "id": "6dW_6K0Pq2xm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpo_configuration = {\n",
        "    \"metric\": {\"name\": \"accuracy\", \"goal\": \"maximize\"},\n",
        "    \"method\": \"grid\",\n",
        "    \"parameters\": {\n",
        "        \"batch_size\": {\n",
        "            \"values\": [32,64,128]\n",
        "        },\n",
        "        \"learning_rate\": {\n",
        "            \"values\": [10e-2,10e-3,10e-4,10e-5]\n",
        "        },\n",
        "        \"hidden_layer\":{\n",
        "            \"values\": [32,64,128]\n",
        "        },\n",
        "        \"epoch\" :{\n",
        "            \"values\": [10]\n",
        "        }\n",
        "\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Mm23Iq3NXa7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment init & config hyperparam\n",
        "deepdriver.create_hpo(exp_name= experiment_name,hpo_config= hpo_configuration)"
      ],
      "metadata": {
        "id": "z93NrRBUsvDm",
        "outputId": "54bcbb3b-fa38-418b-b6a8-a7fb18f7c1eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HPO initialized\n",
            "Team Name=molamola.python\n",
            "Exp Name=cat_dog_cnn_hpo_with_artifact_exp\n",
            "Exp Url=/experi/molamola.python/cat_dog_cnn_hpo_with_artifact_exp/exp/chart\n",
            "optuna study aleady exist !\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('success', 550)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 📚 train your code and send log"
      ],
      "metadata": {
        "id": "CNDciDDURuZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make model"
      ],
      "metadata": {
        "id": "wbFA68eYps1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact={ \n",
        "    \"code\" :\n",
        "    { \n",
        "        \"exp_name\": \"upload_data_code\",\n",
        "        \"type\" : \"CODE\", \n",
        "        \"name\" : \"cnn_1\", \n",
        "        \"file\": \"main.py\", \n",
        "        \"fun\": \"train\"\n",
        "   }\n",
        "}\n"
      ],
      "metadata": {
        "id": "guYZyGrpuOQf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " deepdriver.run_hpo(exp_name=experiment_name, artifact= artifact, count=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4GuWFXW1rHX",
        "outputId": "0c129d5b-4677-41e5-e766-a7f9e9fdd63b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artifact is got! \n",
            " artifact id :{486}\n",
            "Downloading: [./deepdriver/artifact/486/V2/main.py] |██████████████████████████████| [100.0%] [1/1]DeepDriver initialized\n",
            "Team Name=molamola.python\n",
            "Exp Name=cat_dog_cnn_hpo_with_artifact_exp\n",
            "Run Name=run-5\n",
            "Run URL=http://54.180.86.146:9111/experi/molamola.python/cat_dog_cnn_hpo_with_artifact_exp/run-5/run/chart\n",
            "[('batch_size', 128), ('learning_rate', 0.0001), ('hidden_layer', 128), ('epoch', 10)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2023-01-26 07:49:49,787]\u001b[0m Trial 4 failed with parameters: {'batch_size': 128, 'learning_rate': 0.0001, 'hidden_layer': 128, 'epoch': 10} because of the following error: NameError(\"name 'define_model' is not defined\").\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/deepdriver/sdk/experiment.py\", line 209, in <lambda>\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/deepdriver/sdk/experiment.py\", line 214, in objective\n",
            "    def get_wrapped_func(exp_name, team_name, func, config):\n",
            "  File \"<string>\", line 4, in train\n",
            "NameError: name 'define_model' is not defined\n",
            "\u001b[33m[W 2023-01-26 07:49:49,790]\u001b[0m Trial 4 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name 'define_model' is not defined\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/deepdriver/sdk/experiment.py\", line 254, in run_optimize\n",
            "    exec(f'deepdriver.config.{key} = trial.suggest_categorical(\"{key}\", {values})')\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/study.py\", line 425, in optimize\n",
            "    _optimize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
            "    _optimize_sequential(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
            "    frozen_trial = _run_trial(study, func, catch)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
            "    raise func_err\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/deepdriver/sdk/experiment.py\", line 209, in <lambda>\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/deepdriver/sdk/experiment.py\", line 214, in objective\n",
            "    def get_wrapped_func(exp_name, team_name, func, config):\n",
            "  File \"<string>\", line 4, in train\n",
            "NameError: name 'define_model' is not defined\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dn_UkcTT2kvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}